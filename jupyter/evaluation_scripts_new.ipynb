{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#  eval long answer generation metrics\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "rouge=evaluate.load(\"../evaluate_utils/rouge/\")\n",
    "\n",
    "def select_candidate(generated_answer, gold_answers):\n",
    "    max_rouge_score = 0\n",
    "    candidate_idx = -1\n",
    "    if isinstance(gold_answers, str):\n",
    "        return gold_answers\n",
    "    if len(gold_answers) == 1:\n",
    "        return gold_answers[0]\n",
    "    for idx, gold_answer in enumerate(gold_answers):\n",
    "        rouge_score = rouge.compute(predictions=[generated_answer], references=[gold_answer])\n",
    "        if rouge_score[\"rougeL\"] > max_rouge_score:\n",
    "            max_rouge_score = rouge_score[\"rougeL\"]\n",
    "            candidate_idx = idx\n",
    "    return gold_answers[candidate_idx]\n",
    "\n",
    "def mean_rouge(rouge_results):\n",
    "    rouge_results = {k: sum([rouge_result for rouge_result in rouge_results[k]]) / len(rouge_results[\"rouge1\"]) for k in rouge_results.keys()}\n",
    "    return {k: round(v * 100, 2) for k, v in rouge_results.items()}\n",
    "\n",
    "\n",
    "dataset='eli5'\n",
    "split=('test')\n",
    "chat_model=\"qwen72b\"\n",
    "search_engine=\"kiltbm25\"\n",
    "rerank_model=\"e5base\"\n",
    "\n",
    "\n",
    "print(f\"dataset: {dataset}, split: {split}, chat_model: {chat_model}, search_engine: {search_engine}, rerank_model: {rerank_model}\")\n",
    "#  no search chat results\n",
    "no_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "no_search_chat_results=[json.loads(line) for line in open(no_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "no_search_generated_answers=[data_line[f\"{chat_model}_without_search_answer\"] for data_line in no_search_chat_results]\n",
    "\n",
    "if \"answer\" in no_search_chat_results[0]:\n",
    "    gold_answers=[data_line[\"answer\"] for data_line in no_search_chat_results]\n",
    "else:\n",
    "    gold_answers=[data_line[\"long_answers\"] for data_line in no_search_chat_results]\n",
    "\n",
    "# no_search_gold_answers=[]\n",
    "# \n",
    "# for gen, gold in tqdm(zip(no_search_generated_answers, gold_answers), total=len(no_search_generated_answers)):\n",
    "#     no_search_gold_answers.append(select_candidate(gen,gold))\n",
    "# print(\"no search results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=no_search_generated_answers, references=no_search_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  cot chat results\n",
    "cot_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/cot/{chat_model}-{dataset}-{split}.jsonl'\n",
    "cot_chat_results=[json.loads(line) for line in open(cot_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "cot_generated_answers=[data_line[f\"{chat_model}_cot_answer\"] for data_line in cot_chat_results]\n",
    "cot_gold_answers=[]\n",
    "\n",
    "# for gen, gold in tqdm(zip(cot_generated_answers, gold_answers), total=len(cot_generated_answers)):\n",
    "#     cot_gold_answers.append(select_candidate(gen,gold))\n",
    "# print(\"cot results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=cot_generated_answers, references=cot_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "    \n",
    "\n",
    "#  vanilla search chat results\n",
    "if search_engine == \"bing\":\n",
    "    vanilla_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/vanilla_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    vanilla_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/vanilla_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "vanilla_search_results=[json.loads(line) for line in open(vanilla_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "vanilla_search_generated_answers=[data_line[f\"{chat_model}_vanilla_search_answer\"] for data_line in vanilla_search_results]\n",
    "# vanilla_search_gold_answers=[]\n",
    "# \n",
    "# for gen, gold in tqdm(zip(vanilla_search_generated_answers, gold_answers), total=len(vanilla_search_generated_answers)):\n",
    "#     vanilla_search_gold_answers.append(select_candidate(gen,gold))\n",
    "# print(\"vanilla search results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=vanilla_search_generated_answers, references=vanilla_search_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  v0110 rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_model=\"v0115\"\n",
    "v0110_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "v0110_rewrite_search_results=[json.loads(line) for line in open(v0110_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[v0110_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "v0110_judge_generated_answers=[no_search_chat_results[idx][f\"{chat_model}_without_search_answer\"] if knowns[idx] else vanilla_search_results[idx][f\"{chat_model}_vanilla_search_answer\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "v0110_judge_gold_answers=[]\n",
    "for gen, gold in tqdm(zip(v0110_judge_generated_answers, gold_answers), total=len(v0110_judge_generated_answers)):\n",
    "    v0110_judge_gold_answers.append(select_candidate(gen,gold))\n",
    "\n",
    "print(f\"{judge_model} judge results end to end metrics\")\n",
    "rouge_result=rouge.compute(predictions=v0110_judge_generated_answers, references=v0110_judge_gold_answers)\n",
    "print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  gpt4 rewrite chat results\n",
    "if search_engine == \"bing\":\n",
    "    gpt4_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/gpt4_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    gpt4_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/gpt4_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "gpt4_rewrite_search_results=[json.loads(line) for line in open(gpt4_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "gpt4_rewrite_search_generated_answers=[data_line[f\"{chat_model}_gpt4_rewrite_search_answer\"] for data_line in gpt4_rewrite_search_results]\n",
    "# gpt4_rewrite_search_gold_answers=[]\n",
    "# \n",
    "# for gen, gold in tqdm(zip(gpt4_rewrite_search_generated_answers, gold_answers), total=len(gpt4_rewrite_search_generated_answers)):\n",
    "#     gpt4_rewrite_search_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(\"gpt4 rewrite results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=gpt4_rewrite_search_generated_answers, references=gpt4_rewrite_search_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  v0110 judge chat results(only judge whether the retrieval is required)\n",
    "v0110_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "v0110_rewrite_search_results=[json.loads(line) for line in open(v0110_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[v0110_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "v0110_judge_generated_answers=[no_search_chat_results[idx][f\"{chat_model}_without_search_answer\"] if knowns[idx] else gpt4_rewrite_search_results[idx][f\"{chat_model}_gpt4_rewrite_search_answer\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "# v0110_judge_gold_answers=[]\n",
    "# for gen, gold in tqdm(zip(v0110_judge_generated_answers, gold_answers), total=len(v0110_judge_generated_answers)):\n",
    "#     v0110_judge_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(f\"{judge_model} judge results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=v0110_judge_generated_answers, references=gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "\n",
    "# v0105 rewrite chat results\n",
    "rewrite_model=\"v0118tinyllamav0104\"\n",
    "if search_engine == \"bing\":\n",
    "    v0105_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    v0105_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "v0105_rewrite_search_results=[json.loads(line) for line in open(v0105_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "v0105_rewrite_search_generated_answers=[data_line[f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for data_line in v0105_rewrite_search_results]\n",
    "# v0105_rewrite_search_gold_answers=[]\n",
    "# \n",
    "# for gen, gold in tqdm(zip(v0105_rewrite_search_generated_answers, gold_answers), total=len(v0105_rewrite_search_generated_answers)):\n",
    "#     v0105_rewrite_search_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(f\"{rewrite_model} rewrite results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=v0105_rewrite_search_generated_answers, references=v0105_rewrite_search_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  v0110 judge chat results(only judge whether the retrieval is required)\n",
    "v0110_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "v0110_rewrite_search_results=[json.loads(line) for line in open(v0110_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[v0110_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "v0110_judge_generated_answers=[no_search_chat_results[idx][f\"{chat_model}_without_search_answer\"] if knowns[idx] else v0105_rewrite_search_results[idx][f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "# v0110_judge_gold_answers=[]\n",
    "# for gen, gold in tqdm(zip(v0110_judge_generated_answers, gold_answers), total=len(v0110_judge_generated_answers)):\n",
    "#     v0110_judge_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(f\"{judge_model} judge results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=v0110_judge_generated_answers, references=gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "# v0105 rewrite chat results\n",
    "rewrite_model=\"v0119\"\n",
    "if search_engine == \"bing\":\n",
    "    v0105_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    v0105_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "v0105_rewrite_search_results=[json.loads(line) for line in open(v0105_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "v0105_rewrite_search_generated_answers=[data_line[f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for data_line in v0105_rewrite_search_results]\n",
    "# v0105_rewrite_search_gold_answers=[]\n",
    "# \n",
    "# for gen, gold in tqdm(zip(v0105_rewrite_search_generated_answers, gold_answers), total=len(v0105_rewrite_search_generated_answers)):\n",
    "#     v0105_rewrite_search_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(f\"{rewrite_model} rewrite results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=v0105_rewrite_search_generated_answers, references=v0105_rewrite_search_gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})\n",
    "\n",
    "#  v0110 judge chat results(only judge whether the retrieval is required)\n",
    "v0110_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "v0110_rewrite_search_results=[json.loads(line) for line in open(v0110_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[v0110_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "v0110_judge_generated_answers=[no_search_chat_results[idx][f\"{chat_model}_without_search_answer\"] if knowns[idx] else v0105_rewrite_search_results[idx][f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for idx in range(len(v0110_rewrite_search_results))]\n",
    "# v0110_judge_gold_answers=[]\n",
    "# for gen, gold in tqdm(zip(v0110_judge_generated_answers, gold_answers), total=len(v0110_judge_generated_answers)):\n",
    "#     v0110_judge_gold_answers.append(select_candidate(gen,gold))\n",
    "# \n",
    "# print(f\"{judge_model} judge results end to end metrics\")\n",
    "# rouge_result=rouge.compute(predictions=v0110_judge_generated_answers, references=gold_answers)\n",
    "# print({k: round(v * 100, 2) for k, v in rouge_result.items()})"
   ],
   "id": "d350bf115bd06ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  eval short answer matching metrics\n",
    "import string\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from evaluate_utils.rouge_chinese.rouge import Rouge\n",
    "import json\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "import evaluate\n",
    "\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "  def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def calculate_short_answer_EM(generated_answer, gold_answers):\n",
    "    generated_answer=normalize_answer(generated_answer)\n",
    "    match=0\n",
    "    for gold_answer in gold_answers:\n",
    "        gold_answer=normalize_answer(gold_answer)\n",
    "        if gold_answer in generated_answer:\n",
    "            match+=1\n",
    "    return {\n",
    "        \"recall\": match/len(gold_answers),\n",
    "        \"exact_match\": match>0\n",
    "    }\n",
    "            \n",
    "\n",
    "dataset='asqa'\n",
    "split=('test')\n",
    "chat_model=\"qwen72b\"\n",
    "# chat_model=\"llama70b\"\n",
    "search_engine=\"kiltbm25\"\n",
    "rerank_model=\"e5base\"\n",
    "\n",
    "\n",
    "print(f\"dataset: {dataset}, split: {split}, chat_model: {chat_model}, search_engine: {search_engine}, rerank_model: {rerank_model}\")\n",
    "#  no search chat results\n",
    "no_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "no_search_chat_results=[json.loads(line) for line in open(no_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_without_search_answer\"] for data_line in no_search_chat_results]\n",
    "no_search_or_cot_answers=generated_answers\n",
    "\n",
    "if \"short_answers\" in no_search_chat_results[0]:\n",
    "    gold_answers=[data_line[\"short_answers\"] for data_line in no_search_chat_results]\n",
    "else:\n",
    "    if isinstance(no_search_chat_results[0][\"answer\"], list):\n",
    "        gold_answers=[data_line[\"answer\"] for data_line in no_search_chat_results]\n",
    "    else:\n",
    "        gold_answers=[[data_line[\"answer\"]] for data_line in no_search_chat_results]\n",
    "\n",
    "no_search_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(\"no search results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in no_search_em_results])/len(no_search_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in no_search_em_results])/len(no_search_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  cot chat results\n",
    "cot_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/cot/{chat_model}-{dataset}-{split}.jsonl'\n",
    "cot_search_results=[json.loads(line) for line in open(cot_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_cot_answer\"] for data_line in cot_search_results]\n",
    "if \"qwen72b\" in chat_model and \"nq\" not in dataset:\n",
    "    no_search_or_cot_answers=generated_answers\n",
    "\n",
    "cot_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(\"cot results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in cot_em_results])/len(cot_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in cot_em_results])/len(cot_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "\n",
    "#  vanilla search chat results\n",
    "if search_engine == \"bing\":\n",
    "    vanilla_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/vanilla_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    vanilla_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/vanilla_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "vanilla_search_results=[json.loads(line) for line in open(vanilla_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "\n",
    "generated_answers=[data_line[f\"{chat_model}_vanilla_search_answer\"] for data_line in vanilla_search_results]\n",
    "\n",
    "vanilla_search_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(\"vanilla search results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in vanilla_search_em_results])/len(vanilla_search_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in vanilla_search_em_results])/len(vanilla_search_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  v0110 rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_model=\"v0104llama7b\"\n",
    "judge_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "judge_rewrite_search_results=[json.loads(line) for line in open(judge_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[judge_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "generated_answers=[no_search_or_cot_answers[idx] if knowns[idx] else vanilla_search_results[idx][f\"{chat_model}_vanilla_search_answer\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "\n",
    "em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{judge_model} judge results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in em_results])/len(em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in em_results])/len(em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  gpt4 rewrite chat results\n",
    "if search_engine == \"bing\":\n",
    "    gpt4_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/gpt4_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    gpt4_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/gpt4_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "gpt4_rewrite_search_results=[json.loads(line) for line in open(gpt4_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_gpt4_rewrite_search_answer\"] for data_line in gpt4_rewrite_search_results]\n",
    "\n",
    "gpt4_rewrite_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(\"gpt4 rewrite results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in gpt4_rewrite_em_results])/len(gpt4_rewrite_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in gpt4_rewrite_em_results])/len(gpt4_rewrite_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  judge rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "judge_rewrite_search_results=[json.loads(line) for line in open(judge_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[judge_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "generated_answers=[no_search_or_cot_answers[idx] if knowns[idx] else gpt4_rewrite_search_results[idx][f\"{chat_model}_gpt4_rewrite_search_answer\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "\n",
    "em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{judge_model} judge results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in em_results])/len(em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in em_results])/len(em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "\n",
    "# v0105llama7b rewrite chat results\n",
    "rewrite_model=\"v0119\"\n",
    "if search_engine == \"bing\":\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "v0105llama7b_rewrite_search_results=[json.loads(line) for line in open(v0105llama7b_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for data_line in v0105llama7b_rewrite_search_results]\n",
    "\n",
    "v0105llama7b_rewrite_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{rewrite_model} rewrite results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  judge rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "judge_rewrite_search_results=[json.loads(line) for line in open(judge_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[judge_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "generated_answers=[no_search_or_cot_answers[idx] if knowns[idx] else v0105llama7b_rewrite_search_results[idx][f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "\n",
    "em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{judge_model} judge results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in em_results])/len(em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in em_results])/len(em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "# v0105llama7b rewrite chat results\n",
    "rewrite_model=\"v0118llama7b\"\n",
    "if search_engine == \"bing\":\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "v0105llama7b_rewrite_search_results=[json.loads(line) for line in open(v0105llama7b_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for data_line in v0105llama7b_rewrite_search_results]\n",
    "\n",
    "v0105llama7b_rewrite_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{rewrite_model} rewrite results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  judge rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "judge_rewrite_search_results=[json.loads(line) for line in open(judge_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[judge_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "generated_answers=[no_search_or_cot_answers[idx] if knowns[idx] else v0105llama7b_rewrite_search_results[idx][f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "\n",
    "em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{judge_model} judge results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in em_results])/len(em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in em_results])/len(em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "# v0105llama7b rewrite chat results\n",
    "rewrite_model=\"v0118llama7bv0104\"\n",
    "if search_engine == \"bing\":\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "else:\n",
    "    v0105llama7b_rewrite_search_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/{rewrite_model}_rewrite_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "v0105llama7b_rewrite_search_results=[json.loads(line) for line in open(v0105llama7b_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "generated_answers=[data_line[f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for data_line in v0105llama7b_rewrite_search_results]\n",
    "\n",
    "v0105llama7b_rewrite_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{rewrite_model} rewrite results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in v0105llama7b_rewrite_em_results])/len(v0105llama7b_rewrite_em_results) * 100, 2),\n",
    "})\n",
    "\n",
    "#  judge rewrite chat results(only judge whether the retrieval is required)\n",
    "judge_rewrite_search_results_file=f'../user_intent_data/{dataset}/rewrite/{judge_model}/{judge_model}-{dataset}-{split}.jsonl'\n",
    "judge_rewrite_search_results=[json.loads(line) for line in open(judge_rewrite_search_results_file, \"r\", encoding=\"utf-8\")]\n",
    "knowns=[judge_rewrite_search_results[idx][f'{judge_model}_rewrite'][\"known\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "generated_answers=[no_search_or_cot_answers[idx] if knowns[idx] else v0105llama7b_rewrite_search_results[idx][f\"{chat_model}_{rewrite_model}_rewrite_search_answer\"] for idx in range(len(judge_rewrite_search_results))]\n",
    "\n",
    "em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "print(f\"{judge_model} judge results short answer matching metrics\")\n",
    "print({\n",
    "    \"recall\": round(sum([item[\"recall\"] for item in em_results])/len(em_results) * 100, 2),\n",
    "    \"exact_match\": round(sum([1 if item[\"exact_match\"] else 0 for item in em_results])/len(em_results) * 100, 2),\n",
    "})\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1cd830c70ed97f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
