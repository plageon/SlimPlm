{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  filter out known/unknown results according to short answers only based on no search results\n",
    "datasets=[\"asqa\", \"nq\", \"trivia-qa\", \"hotpot-qa\"]\n",
    "split=('train')\n",
    "chat_model=\"llama7b\"\n",
    "search_engine=\"kiltbm25\"\n",
    "rerank_model=\"e5base\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "  def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def calculate_short_answer_EM(generated_answer, gold_answers):\n",
    "    generated_answer=normalize_answer(generated_answer)\n",
    "    match=0\n",
    "    for gold_answer in gold_answers:\n",
    "        gold_answer=normalize_answer(gold_answer)\n",
    "        if gold_answer in generated_answer:\n",
    "            match+=1\n",
    "    return {\n",
    "        \"recall\": match/len(gold_answers),\n",
    "        \"exact_match\": match>0\n",
    "    }\n",
    "      \n",
    "for dataset in datasets:\n",
    "    # print(f\"dataset: {dataset}, split: {split}, chat_model: {chat_model}, search_engine: {search_engine}, rerank_model: {rerank_model}\")\n",
    "    #  no search chat results\n",
    "    if split == \"trainmore\":\n",
    "        without_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-train.jsonl'\n",
    "        without_search_chat_results_file2=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-trainmore.jsonl'\n",
    "        if os.path.exists(without_search_chat_results_file2):\n",
    "            without_search_chat_results=[json.loads(line) for line in open(without_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "            without_search_chat_results.extend([json.loads(line) for line in open(without_search_chat_results_file2, \"r\", encoding=\"utf-8\")])\n",
    "        else:\n",
    "            without_search_chat_results=[json.loads(line) for line in open(without_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "    else:\n",
    "        without_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "        without_search_chat_results=[json.loads(line) for line in open(without_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "    generated_answers=[data_line[f\"{chat_model}_without_search_answer\"] for data_line in without_search_chat_results]\n",
    "    \n",
    "    if len(without_search_chat_results) == 0:\n",
    "        continue\n",
    "    if \"short_answers\" in without_search_chat_results[0]:\n",
    "        gold_answers=[data_line[\"short_answers\"] for data_line in without_search_chat_results]\n",
    "    else:\n",
    "        if isinstance(without_search_chat_results[0][\"answer\"], list):\n",
    "            gold_answers=[data_line[\"answer\"] for data_line in without_search_chat_results]\n",
    "        else:\n",
    "            gold_answers=[[data_line[\"answer\"]] for data_line in without_search_chat_results]\n",
    "    \n",
    "    without_search_em_results = [calculate_short_answer_EM(generated_answers[idx], gold_answers[idx]) for idx in range(len(generated_answers))]\n",
    "    \n",
    "        \n",
    "    filtered_gpt4_rewrite=[]\n",
    "    search_tags=[]\n",
    "    sample_count=0\n",
    "\n",
    "    thresholds={\n",
    "        \"asqa\": 0.5,\n",
    "        \"qampari\": 0.7,\n",
    "        \"nq\": 0.5,\n",
    "        \"trivia-qa\": 0.5,\n",
    "        \"2wiki\": 0.5,\n",
    "        \"musique\": 0.5,\n",
    "        \"hotpot-qa\": 0.5,\n",
    "    }\n",
    "    threshold=thresholds[dataset]\n",
    "    for idx in range(len(without_search_em_results)):\n",
    "        without_search_chat_results[idx][\"dataset\"]=dataset\n",
    "        if without_search_em_results[idx][\"recall\"] > threshold:\n",
    "            search_tag=\"<known> \"\n",
    "            without_search_chat_results[idx][\"known\"] = True\n",
    "            sample_count+=1\n",
    "        else:\n",
    "            search_tag=\"<unknown> \"\n",
    "            without_search_chat_results[idx][\"known\"] = False\n",
    "        # if gpt4_rewrite_em_results[idx][\"recall\"] < vanilla_search_em_results[idx][\"recall\"]:\n",
    "        #     search_tag+=\"<original>\"\n",
    "        #     without_search_chat_data[idx][\"rewrite\"] = False\n",
    "        # else:\n",
    "        #     search_tag+=\"<rewrite>\"\n",
    "        #     without_search_chat_data[idx][\"rewrite\"] = True\n",
    "        #  drop some samples if recall are all equal\n",
    "        # if without_search_em_results[idx][\"recall\"] == vanilla_search_em_results[idx][\"recall\"] and without_search_em_results[idx][\"recall\"] == gpt4_rewrite_em_results[idx][\"recall\"]:\n",
    "        #     continue\n",
    "        # unknow samples are no more than known samples\n",
    "        if \"unknown\" in search_tag:\n",
    "            if sample_count > 0:\n",
    "                sample_count-=1\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        search_tags.append(search_tag)\n",
    "        # without_search_chat_data[idx][\"search_tags\"] = search_tag\n",
    "        filtered_gpt4_rewrite.append(without_search_chat_results[idx])\n",
    "        #  filtered sample should be no more than 4000\n",
    "        # filtered_gpt4_rewrite=filtered_gpt4_rewrite[:5000]\n",
    "        #  make sure there are no duplicated ids\n",
    "        filtered_ids=[data_line[\"id\"] for data_line in filtered_gpt4_rewrite]\n",
    "        assert len(filtered_ids) == len(set(filtered_ids))\n",
    "        \n",
    "    print(f\"filtered {len(filtered_gpt4_rewrite)} data, total {len(without_search_chat_results)} data\")\n",
    "    print(f\"dataset: {dataset}, split: {split}, chat_model: {chat_model}, search_engine: {search_engine}, rerank_model: {rerank_model}\")\n",
    "    search_tag_num_dict={k: search_tags.count(k) for k in set(search_tags)}\n",
    "    print(search_tag_num_dict)\n",
    "    print(f\"dropped {len(without_search_chat_results)-len(filtered_gpt4_rewrite)} samples\")\n",
    "    if not os.path.exists(f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/\"):\n",
    "        os.makedirs(f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/\", exist_ok=True)\n",
    "    #  save filtered results to mixed dataset\n",
    "    mixed_dataset_file=f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/filtered-{dataset}-{split}.jsonl\"\n",
    "    with open(mixed_dataset_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx in range(len(filtered_gpt4_rewrite)):\n",
    "            f.write(json.dumps(filtered_gpt4_rewrite[idx], ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  filter training data for SKR\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "random.seed(4545)\n",
    "\n",
    "datasets=(\"asqa\", \"nq\", \"trivia-qa\", \"musique\")\n",
    "split=\"trainfew\"\n",
    "chat_model=\"qwen72b\"\n",
    "search_engine=\"kiltbm25\"\n",
    "rerank_model=\"e5base\"\n",
    "\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "  def remove_articles(text):\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def calculate_short_answer_EM(generated_answer, gold_answers):\n",
    "    generated_answer=normalize_answer(generated_answer)\n",
    "    match=0\n",
    "    for gold_answer in gold_answers:\n",
    "        gold_answer=normalize_answer(gold_answer)\n",
    "        if gold_answer in generated_answer:\n",
    "            match+=1\n",
    "    return {\n",
    "        \"recall\": match/len(gold_answers),\n",
    "        \"exact_match\": match>0\n",
    "    }\n",
    "\n",
    "for dataset in datasets:\n",
    "    no_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/without_search/{chat_model}-{dataset}-{split}.jsonl'\n",
    "    no_search_chat_results=[json.loads(line) for line in open(no_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "    if \"short_answers\" in no_search_chat_results[0]:\n",
    "        gold_answers=[data_line[\"short_answers\"] for data_line in no_search_chat_results]\n",
    "    else:\n",
    "        if isinstance(no_search_chat_results[0][\"answer\"], list):\n",
    "            gold_answers=[data_line[\"answer\"] for data_line in no_search_chat_results]\n",
    "        else:\n",
    "            gold_answers=[[data_line[\"answer\"]] for data_line in no_search_chat_results]\n",
    "            \n",
    "    no_search_generated_answers=[data_line[f\"{chat_model}_without_search_answer\"] for data_line in no_search_chat_results]\n",
    "    no_search_em_results = [calculate_short_answer_EM(no_search_generated_answers[idx], gold_answers[idx]) for idx in range(len(no_search_generated_answers))]\n",
    "    \n",
    "    vanilla_search_chat_results_file=f'../user_intent_data/{dataset}/{chat_model}/{search_engine}/vanilla_search/{rerank_model}-{chat_model}-{dataset}-{split}.jsonl'\n",
    "    vanilla_search_chat_results=[json.loads(line) for line in open(vanilla_search_chat_results_file, \"r\", encoding=\"utf-8\")]\n",
    "    vanilla_search_generated_answers=[data_line[f\"{chat_model}_vanilla_search_answer\"] for data_line in vanilla_search_chat_results]\n",
    "    vanilla_search_em_results = [calculate_short_answer_EM(vanilla_search_generated_answers[idx], gold_answers[idx]) for idx in range(len(vanilla_search_generated_answers))]\n",
    "    \n",
    "    #  filter out known/unknown results according to short answers\n",
    "    #  if no search results >= vanilla search results, then it is known\n",
    "    #  if no search results < vanilla search results, then it is unknown\n",
    "    filtered_gpt4_rewrite=[]\n",
    "    search_tags=[]\n",
    "    sample_count=0\n",
    "    if \"recall\" in no_search_em_results[0]:\n",
    "        for idx in range(len(no_search_em_results)):\n",
    "            if no_search_em_results[idx][\"recall\"] > vanilla_search_em_results[idx][\"recall\"]:\n",
    "                search_tag=\"<known> \"\n",
    "                no_search_chat_results[idx][\"known\"] = True\n",
    "                sample_count+=1\n",
    "            elif no_search_em_results[idx][\"recall\"] < vanilla_search_em_results[idx][\"recall\"]:\n",
    "                search_tag=\"<unknown> \"\n",
    "                no_search_chat_results[idx][\"known\"] = False\n",
    "            else:\n",
    "                continue\n",
    "            # if both recall are 0, then drop the sample\n",
    "            if no_search_em_results[idx][\"recall\"] == 0 and vanilla_search_em_results[idx][\"recall\"] == 0:\n",
    "                continue\n",
    "            filtered_gpt4_rewrite.append(no_search_chat_results[idx])\n",
    "            search_tags.append(search_tag)\n",
    "    elif \"rouge\" in no_search_em_results[0]:\n",
    "        for idx in range(len(no_search_em_results)):\n",
    "            if no_search_em_results[idx][\"rouge\"][\"rougeL\"] > vanilla_search_em_results[idx][\"rouge\"][\"rougeL\"]:\n",
    "                search_tag=\"<known> \"\n",
    "                no_search_chat_results[idx][\"known\"] = True\n",
    "                sample_count+=1\n",
    "            elif no_search_em_results[idx][\"rouge\"][\"rougeL\"] < vanilla_search_em_results[idx][\"rouge\"][\"rougeL\"]:\n",
    "                search_tag=\"<unknown> \"\n",
    "                no_search_chat_results[idx][\"known\"] = False\n",
    "            else:\n",
    "                continue\n",
    "    print(f\"filtered {len(filtered_gpt4_rewrite)} data\")\n",
    "    print(f\"dataset: {dataset}, split: {split}, chat_model: {chat_model}, search_engine: {search_engine}, rerank_model: {rerank_model}\")\n",
    "    search_tag_num_dict={k: search_tags.count(k) for k in set(search_tags)}\n",
    "    print(search_tag_num_dict)\n",
    "    if not os.path.exists(f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/\"):\n",
    "        os.makedirs(f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/\", exist_ok=True)\n",
    "    #  save filtered results to mixed dataset\n",
    "    mixed_dataset_file=f\"../user_intent_data/mixed/{dataset}/{chat_model}/{search_engine}/filtered-{dataset}-{split}.jsonl\"\n",
    "    with open(mixed_dataset_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx in range(len(filtered_gpt4_rewrite)):\n",
    "            f.write(json.dumps(filtered_gpt4_rewrite[idx], ensure_ascii=False) + \"\\n\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cc2edf60b276a9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
